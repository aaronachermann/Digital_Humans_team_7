{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":925175,"sourceType":"datasetVersion","datasetId":498911},{"sourceId":8702511,"sourceType":"datasetVersion","datasetId":5219537},{"sourceId":11702963,"sourceType":"datasetVersion","datasetId":7345700},{"sourceId":11704419,"sourceType":"datasetVersion","datasetId":7346664},{"sourceId":11771923,"sourceType":"datasetVersion","datasetId":7390635},{"sourceId":11800027,"sourceType":"datasetVersion","datasetId":7410260},{"sourceId":11800555,"sourceType":"datasetVersion","datasetId":7410617}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#clone and install dependencies\n!pip install xformers\n!pip install bitsandbytes\n!pip uninstall torch torchvision -y\n\n!git clone https://github.com/huggingface/diffusers \n!cd diffusers && pip install . && cd examples/dreambooth && pip install -r requirements.txt\n\n!pip install --upgrade peft\n!pip install wandb # for outputting images mid training","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#create environment\n!accelerate config default\n\nimport os\nfrom diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\nfrom transformers import CLIPProcessor, CLIPModel\nimport torch\nimport torchvision.transforms as T\nimport torch.nn.functional as F\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport timm\nimport numpy as np\n\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# store the weights on huggingface\nfrom huggingface_hub import login\n\n# Use your Hugging Face token for login\nlogin(token=\"[YOUR_HF_TOKEN]\")\n\n# Set the W&B configuration via environment variables\nos.environ[\"WANDB_MODE\"] = \"online\"  \nos.environ[\"WANDB_API_KEY\"] = \"[YOUR_W&B_API_KEY]\"  # Replace with your W&B API key ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom transformers import CLIPModel, CLIPProcessor\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport torch\n\n# 1) Run Python garbage collection\ngc.collect()\n\n# 2) Release all cached GPU memory back to the OS\ntorch.cuda.empty_cache()\n\n# 3) (Optional) If you want to reset peak-memory stats\ntorch.cuda.reset_peak_memory_stats()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = \"/kaggle/working/\"\n\nfolders = [\n    \"tmp\",\n    \"tmp/modified_pretrained_model\",\n    \"tmp/generated_images\"\n]\n\nfor folder in folders:\n    folder_path = os.path.join(base_path, folder)\n    os.makedirs(folder_path, exist_ok=True)\n    print(f\"Cartella creata: {folder_path}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nfrom datetime import datetime\nimport itertools\nimport subprocess\nimport torch\nimport torch.nn.functional as F\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\nfrom transformers import CLIPProcessor, CLIPModel\nfrom huggingface_hub import login\nimport wandb\n\nimport torch, gc\ntorch.cuda.empty_cache()\ngc.collect()\n\n\n# Python script for Kaggle notebook to extract X images from a source directory\n\nimport os\nimport shutil\nimport random\n\n\nimport os\nimport shutil\nimport random\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nclip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\nclip_embeddings = clip_model.text_model.embeddings.token_embedding\nclip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\nclip_tokenizer = clip_processor.tokenizer\n\n\ndef get_embedding(text):\n    inputs = clip_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    with torch.no_grad():\n        txt_emb = clip_model.get_text_features(**inputs)\n    return txt_emb\n\n\ndef extract_images(src_dir: str, num_images: int, dataset_name: str) -> str:\n    \"\"\"\n    Extracts num_images random images from src_dir, copies them to a new folder\n    '{num_images}_{dataset_name}' in the working directory and returns the absolute path\n    of the created folder. If the folder already exists, it is deleted and recreated.\n    \"\"\"\n\n    output_folder = f\"{num_images}_{dataset_name}\"\n\n    if os.path.exists(output_folder):\n        shutil.rmtree(output_folder)\n\n    os.makedirs(output_folder, exist_ok=True)\n\n    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tif', '.tiff'}\n\n    all_images = [\n        filename for filename in os.listdir(src_dir)\n        if os.path.splitext(filename)[1].lower() in image_extensions\n    ]\n\n    if len(all_images) < num_images:\n        raise ValueError(\n            f\"Richieste {num_images} immagini ma ne ho trovate solo {len(all_images)} in {src_dir}.\"\n        )\n\n    # Randomly select num_images images\n    selected_images = random.sample(all_images, num_images)\n    print(f\"Selezionate {len(selected_images)} immagini in '{output_folder}'\")\n\n    for image in selected_images:\n        shutil.copy(\n            os.path.join(src_dir, image),\n            os.path.join(output_folder, image)\n        )\n\n    return os.path.abspath(output_folder)\n\n\n\n# 3) (Optional) If you want to reset peak-memory stats\ntorch.cuda.reset_peak_memory_stats()\n\n# Configuration\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nos.environ[\"WANDB_MODE\"] = \"online\"\nos.environ[\"WANDB_API_KEY\"] = \"e058eb869ff54a4dbade3f7a9ea6820490a46c36\"\n\n# Login to Hugging Face\nlogin(token=\"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\")\n\nclass DreamBoothStudy:\n    def __init__(self):\n        # Study parameters\n        self.nr_images_list = [5,30,70]\n        self.nr_class_images_list = [5, 30, 70]\n        self.lr = [2e-6,5e-6]\n        self.max_train_steps = 200\n        self.new_token = \"[V]\"\n        \n        \n        # Dataset configurations\n        self.datasets = {\n            \"bill_cosby\": {\n                \"images_dir\": \"/kaggle/input/facescrub-full/actor_faces/Bill_Cosby\",\n                \"instance_prompt\": \"a photo of [V] person\",\n                \"validation_prompt\": \"a photo of [V] person in a garden\",\n                \"label\": \"bill cosby\",  # or specific name\n                \"class_prompt\": \"a photo of a person\"\n            },\n            \"golden_retriever_dog\": {\n                \"images_dir\": \"/kaggle/input/dog-breed-image-dataset/dataset/Golden_Retriever\", \n                \"instance_prompt\": \"a photo of [V] dog\",\n                \"validation_prompt\": \"a photo of [V] dog in a garden\",\n                \"label\": \"golden retriever\",\n                \"class_prompt\": \"a photo of a dog\"\n            }\n        }\n        \n        # Results storage\n        self.results = []\n        \n    def setup_base_model(self):\n        \"\"\"Setup and prepare the base Stable Diffusion model\"\"\"\n        print(\"Setting up base model...\")\n        \n        # Load base model\n        pretrained_model = StableDiffusionPipeline.from_pretrained(\n            \"runwayml/stable-diffusion-v1-5\",\n            torch_dtype=torch.float16,\n        ).to(\"cuda\")\n\n            # Memory optimizations\n        pretrained_model.enable_attention_slicing()\n        pretrained_model.enable_xformers_memory_efficient_attention()\n        pretrained_model.enable_model_cpu_offload()\n        pretrained_model.unet.enable_gradient_checkpointing()\n        \n        # Add token\n        pretrained_model.tokenizer.add_tokens(self.new_token)\n        pretrained_model.text_encoder.resize_token_embeddings(len(pretrained_model.tokenizer))\n        pretrained_model.save_pretrained(\"/kaggle/working/tmp/modified_pretrained_model\")\n        \n        print(\"Base model setup complete!\")\n        return pretrained_model\n    \n    def train_model(self, dataset_name, nr_images, nr_class_images, lr, experiment_id):\n        \"\"\"Train DreamBooth LoRA model with specific parameters\"\"\"\n        \n        dataset_config = self.datasets[dataset_name]\n        output_dir = f\"/kaggle/working/tmp/dreambooth-model-{experiment_id}\"\n        #create folder\n        # Esempio di utilizzo in un notebook Kaggle\n        folder_path = extract_images(dataset_config['images_dir'], nr_images, dataset_name)\n        print(\"folder_path:\", folder_path)\n\n\n\n        # Prepare training command\n     \n        cmd = [\n            \"accelerate\", \"launch\",\n            \"--num_processes\", \"1\",\n            \"/kaggle/working/diffusers/examples/dreambooth/train_dreambooth_lora.py\",\n            f\"--pretrained_model_name_or_path=/kaggle/working/tmp/modified_pretrained_model\",\n            f\"--instance_data_dir={folder_path}\",\n            f\"--output_dir={output_dir}\",\n            f\"--instance_prompt={dataset_config['instance_prompt']}\",\n            \"--mixed_precision=bf16\",\n            \"--train_batch_size=1\",\n            \"--gradient_checkpointing\",\n            \"--resolution=128\",\n            \"--gradient_accumulation_steps=1\",\n            \"--checkpointing_steps=100\",\n            f\"--learning_rate={lr}\",\n            \"--report_to=wandb\",\n            \"--lr_scheduler=constant\",\n            \"--lr_warmup_steps=0\",\n            f\"--max_train_steps={self.max_train_steps}\",\n            f\"--validation_prompt={dataset_config['validation_prompt']}\",\n            \"--validation_epochs=50\",\n            \"--seed=0\",\n            f\"--num_class_images={nr_class_images}\",\n            f\"--class_prompt={dataset_config['class_prompt']}\",                  \n        ]\n\n        \n        print(f\"Training model with parameters:\")\n        print(f\"  Dataset: {dataset_name}\")\n        print(f\"  Images: {nr_images}\")\n        print(f\"  Class Images: {nr_class_images}\")\n        print(f\"  Learning rate: {lr}\")\n        \n        # Run training\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 1 hour timeout\n            if result.returncode != 0:\n                print(f\"Training failed: {result.stderr}\")\n                return None\n            print(\"Training completed successfully!\")\n            return output_dir\n        except subprocess.TimeoutExpired:\n            print(\"Training timed out!\")\n            return None\n        except Exception as e:\n            print(f\"Training error: {e}\")\n            return None\n    \n    def load_trained_model(self, output_dir):\n        \"\"\"Load the trained model for inference\"\"\"\n        try:\n            # Load base pipeline\n            pipe = StableDiffusionPipeline.from_pretrained(\n                \"/kaggle/working/tmp/modified_pretrained_model\",\n                torch_dtype=torch.float16\n            ).to(\"cuda\")\n            \n            # Load LoRA weights\n            pipe.unet.load_attn_procs(output_dir)\n\n            # assume `pipe` is your StableDiffusionPipeline\n            pipe.enable_attention_slicing()                   # slices attention for lower peak usage\n            pipe.enable_model_cpu_offload()                   # offloads parts to CPU when idle\n\n            \n            return pipe\n        except Exception as e:\n            print(f\"Error loading trained model: {e}\")\n            return None\n    \n    def compute_cosine_similarity_prompt_image(self, pipe, prompt, image):\n        \"\"\"Compute cosine similarity between prompt and generated image using CLIP\"\"\"\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        \n        # Ensure image is in RGB format\n        if not isinstance(image, Image.Image):\n            image = Image.fromarray(image).convert(\"RGB\")\n        elif image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n            \n        txt_emb = get_embedding(prompt)\n     \n        # Process inputs\n        inputs_img = clip_processor(images=image, return_tensors=\"pt\").to(device)\n        \n        with torch.no_grad():\n            # Get embeddings\n            image_emb = clip_model.get_image_features(**inputs_img)\n  \n        # Normalize and compute similarity\n        image_emb = F.normalize(image_emb, p=2, dim=-1)\n        txt_emb = F.normalize(txt_emb, p=2, dim=-1)\n        \n        cos_sim = torch.matmul(image_emb, txt_emb.T).item()\n        return cos_sim\n    \n    def compute_cosine_similarity_label_token(self, pipe, label, token):\n        \"\"\"Compute cosine similarity between label and token using text encoder\"\"\"\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        label_emb = get_embedding(label)\n        token_emb = get_embedding(token)\n        \n        \n        # Normalize and compute similarity\n        label_emb = F.normalize(label_emb, p=2, dim=-1)\n        token_emb = F.normalize(token_emb, p=2, dim=-1)\n        \n        cos_sim = torch.matmul(label_emb, token_emb.T).item()\n        return cos_sim\n    \n    def run_inference_and_evaluate(self, pipe, dataset_name, nr_images, nr_class_images, lr):\n        \"\"\"Run inference and compute similarity metrics\"\"\"\n        dataset_config = self.datasets[dataset_name]\n        \n        # Generate image\n        prompt = dataset_config['validation_prompt']\n        try:\n            image = pipe(prompt, num_inference_steps=50, guidance_scale=7.0).images[0]\n            \n            # Compute similarities\n            prompt_image_sim = self.compute_cosine_similarity_prompt_image(pipe, prompt, image)\n            label_token_sim = self.compute_cosine_similarity_label_token(pipe, dataset_config['label'], self.new_token)\n            \n            # Save result\n            result = {\n                'dataset': dataset_name,\n                'nr_images': nr_images,\n                'nr_class_images': nr_class_images,\n                'lr': lr,\n                'prompt_image_similarity': prompt_image_sim,\n                'label_token_similarity': label_token_sim,\n                'timestamp': datetime.now().isoformat()\n            }\n            \n            self.results.append(result)\n            \n            # Save image for visual inspection\n            image_path = f\"/kaggle/working/tmp/generated_images/{dataset_name}_{nr_images}_{nr_class_images}_{lr}.png\"\n            os.makedirs(os.path.dirname(image_path), exist_ok=True)\n            image.save(image_path)\n            print(f\"Prompt: {prompt},  Label: {dataset_config['label']},  Token: {self.new_token}\")\n\n            print(f\"Results - Prompt-Image Sim: {prompt_image_sim:.4f}, Label-Token Sim: {label_token_sim:.4f}\")\n            return result\n            \n        except Exception as e:\n            print(f\"Error in inference/evaluation: {e}\")\n            return None\n    \n    def save_results(self):\n        \"\"\"Save results to JSON and CSV files\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        \n        # Save to JSON\n        json_path = f\"/kaggle/working/tmp/dreambooth_study_results_{timestamp}.json\"\n        with open(json_path, 'w') as f:\n            json.dump(self.results, f, indent=2)\n        \n        # Save to CSV\n        df = pd.DataFrame(self.results)\n        csv_path = f\"/kaggle/working/tmp/dreambooth_study_results_{timestamp}.csv\"\n        df.to_csv(csv_path, index=False)\n        \n        print(f\"Results saved to: {json_path} and {csv_path}\")\n        return df\n    \n    def run_complete_study(self):\n        \"\"\"Run the complete study with all parameter combinations\"\"\"\n        print(\"Starting DreamBooth LoRA Study...\")\n        \n        # Setup base model\n        base_model = self.setup_base_model()\n        \n        # Get all parameter combinations\n        combinations = list(itertools.product(\n            self.datasets.keys(),\n            self.nr_images_list,\n            self.nr_class_images_list,\n            self.lr\n        ))\n        \n        total_experiments = len(combinations)\n        print(f\"Total experiments to run: {total_experiments}\")\n        \n        for i, (dataset_name, nr_images, nr_class_images, lr) in enumerate(combinations):\n            print(f\"\\n--- Experiment {i+1}/{total_experiments} ---\")\n            \n            experiment_id = f\"{dataset_name}_{nr_images}_{nr_class_images}_{lr}_{i}\"\n   \n            # Train model\n            output_dir = self.train_model(dataset_name, nr_images, nr_class_images, lr, experiment_id)\n            \n            if output_dir is None:\n                print(\"Skipping evaluation due to training failure\")\n                continue\n            \n            # Load trained model\n            pipe = self.load_trained_model(output_dir)\n            if pipe is None:\n                print(\"Skipping evaluation due to model loading failure\")\n                continue\n            \n            # Run evaluation\n            result = self.run_inference_and_evaluate(pipe, dataset_name, nr_images, nr_class_images, lr)\n            \n            # Clean up GPU memory\n            del pipe\n            torch.cuda.empty_cache()\n            \n            # Save intermediate results\n            if (i + 1) % 5 == 0:  # Save every 5 experiments\n                self.save_results()\n        \n        # Save final results\n        df = self.save_results()\n        print(\"\\nStudy completed!\")\n        return df\n    \n    def analyze_results(self, df=None):\n        \"\"\"Analyze and visualize the results\"\"\"\n        if df is None:\n            df = pd.DataFrame(self.results)\n        \n        print(\"\\n--- Results Analysis ---\")\n        \n        # Summary statistics\n        print(\"\\nSummary Statistics:\")\n        print(df.groupby('dataset')[['prompt_image_similarity', 'label_token_similarity']].describe())\n        \n        # Best configurations\n        print(\"\\nBest configurations by prompt-image similarity:\")\n        best_prompt_image = df.loc[df.groupby('dataset')['prompt_image_similarity'].idxmax()]\n        print(best_prompt_image[['dataset', 'nr_images', 'nr_class_images', 'lr', 'prompt_image_similarity']])\n        \n        print(\"\\nBest configurations by label-token similarity:\")\n        best_label_token = df.loc[df.groupby('dataset')['label_token_similarity'].idxmax()]\n        print(best_label_token[['dataset', 'nr_images', 'nr_class_images', 'lr', 'label_token_similarity']])\n        \n        # Create visualizations\n        self.create_visualizations(df)\n        \n        return df\n    \n    def create_visualizations(self, df):\n        \"\"\"Create visualization plots\"\"\"\n        import seaborn as sns\n        \n        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n        \n        # Plot 1: Prompt-Image Similarity by number of images\n        sns.boxplot(data=df, x='nr_images', y='prompt_image_similarity', hue='dataset', ax=axes[0,0])\n        axes[0,0].set_title('Prompt-Image Similarity by Number of Images')\n        \n        # Plot 2: Label-Token Similarity by number of images  \n        sns.boxplot(data=df, x='nr_images', y='label_token_similarity', hue='dataset', ax=axes[0,1])\n        axes[0,1].set_title('Label-Token Similarity by Number of Images')\n        \n        # Plot 3: Similarities by lr\n        sns.boxplot(data=df, x='lr', y='prompt_image_similarity', hue='dataset', ax=axes[1,0])\n        axes[1,0].set_title('Prompt-Image Similarity by Learning Rate')\n        \n        # Plot 4: Similarities by class images\n        sns.boxplot(data=df, x='nr_class_images', y='label_token_similarity', hue='dataset', ax=axes[1,1])\n        axes[1,1].set_title('Label-Token Similarity by Number of Class Images')\n        \n        plt.tight_layout()\n        plt.savefig('/tmp/dreambooth_study_analysis.png', dpi=300, bbox_inches='tight')\n        plt.show()\n\n# Usage example\nif __name__ == \"__main__\":\n    # Initialize study\n    study = DreamBoothStudy()\n    \n    # Update dataset paths (you need to set these)\n\n    study.datasets[\"bill_cosby\"][\"images_dir\"] = \"/kaggle/input/facescrub-full/actor_faces/Bill_Cosby\"\n    study.datasets[\"golden_retriever_dog\"][\"images_dir\"] = \"/kaggle/input/dog-breed-image-dataset/dataset/Golden_Retriever\"\n    \n    results_df = study.run_complete_study()\n    study.analyze_results(results_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}